## Unreleased

---

# 사주 응답 프롬프트(가독성/규칙 일관성) 개선

## 📋 개요
십이운성 누락, `[MODE: ...]` 노출, 과도한 장문/중복 규칙 등으로 인해 응답 품질이 흔들리던 문제를 개선했습니다. 프롬프트 내 중복/모순을 제거하고, **문단 분리/근거 분리** 등 가독성 규칙을 명확히 했습니다.

---

## 1. 십이운성(sibi_unseong) 누락 방지 규칙 정리

### 1.1 문제점
- 십이운성 “반드시 포함” 지시가 여러 군데에 중복/분산되어 있었고, 일부는 서로 다른 표현으로 반복되어 유지보수성과 효율이 떨어짐

### 1.2 수정 내용
- 십이운성 포함 규칙을 **핵심 규칙 1곳**으로 모으고, “읽기 우선순위(3)”에 따라 값을 읽도록 단일화
- SAJU_EXPLAIN/SAJU_STRUCTURED에서는 **중복된 JSON 경로 나열**을 제거하고, “데이터가 있으면 1회 이상 포함 / 없으면 ‘데이터 없음’ 처리”로 단순화

---

## 2. `[MODE: ...]` 헤더 노출/모순 규칙 제거

### 2.1 문제점
- 프롬프트 내부에 “`[MODE: ...]`를 출력한다/출력하지 않는다”가 동시에 존재해, 실제 응답에서 `[MODE: SAJU_EXPLAIN]` 같은 헤더가 노출되는 원인이 됨

### 2.2 수정 내용
- `[MODE: ...]` 출력 강제 규칙과 관련된 중복 문구를 제거하고,
  “`[MODE: XXX]` 태그는 내부 분기용이므로 출력하지 않는다” 규칙만 유지

---

## 3. 응답 가독성 개선(문단 분리/근거 분리)

### 3.1 수정 내용
- SAJU_EXPLAIN에서 **2~4문장 단위 문단 분리 + 문단 사이 빈 줄** 권장 규칙 유지/정리
- 응답 마지막의 `"근거:"` 섹션을 **본문과 별도 문단으로 분리**하도록 명시

---

## 4. 프롬프트 중복 제거 및 효율 개선

### 4.1 수정 내용
- “입문자 규칙”, “십이운성 체크리스트” 등 **중복 블록 삭제/통합**
- 브릿지(bridge) 출력 규칙을 단순화(브릿지는 있으면 첫 줄에 출력)

---

## 5. 수정된 파일 목록

### 5.1 functions/prompts/saju_prompts.py
- 십이운성 포함 규칙 단일화 및 중복 제거
- `[MODE: ...]` 출력 강제/모순 규칙 제거
- 문단 분리/근거 분리 규칙 정리

---

# 대화 회귀 시스템 v4.0 (LLM 의미 판정 구조)

## 📋 개요
Rule/마커 기반 회귀 판정의 한계를 해결하기 위해, **모든 회귀 판정을 LLM 의미 기반으로 전환**했습니다. 키워드 사전 유지보수 부담을 제거하고, 의미적으로 명확한 회귀 질문을 더 정확하게 감지할 수 있게 되었습니다.

---

## 1. 회귀 판정 시스템 전환 (Rule → LLM)

### 1.1 문제점
- **v3.0 (Gate+Boost 구조)**: 키워드/마커 기반 판정으로 "둘중에 하나만 고르라면?" 같은 의미적 회귀를 놓침
- 키워드 사전 유지보수 부담 및 오탐/미탐 발생
- Rule 기반 로직이 100줄 이상으로 복잡해짐

### 1.2 수정 내용
- **Rule/마커 기반 Step A 완전 제거**
- **LLM 의미 기반 회귀 판정기 도입** (`_llm_detect_continuation`)
- 보수적 임계치 유지: `confidence ≥ 0.75`에서만 회귀로 판정
- 의미적으로 명확한 회귀 질문을 더 정확하게 감지

---

## 2. 최종 Pipeline 구조

### 2.1 3단계 처리 흐름
```
Step A: LLM 회귀 판정 (의미 기반)
  → 입력: 직전 assistant 답변 + 현재 user 질문
  → 출력: {is_continuation, confidence, reason}
  → 임계치: confidence ≥ 0.75

Step B: LLM 결론 정제 (Step A 통과 시)
  → 입력: 최근 assistant 2~4개 + 현재 질문
  → 출력: {decisions, key_points, open_questions, constraints, confidence}
  → 임계치: confidence ≥ 0.6

Step C: 조건부 주입
  → Step B confidence ≥ 0.6일 때만
  → 최대 3줄 제한으로 간결하게 주입
```

### 2.2 핵심 원칙
- **추측 금지**: 텍스트 근거가 약하면 False
- **보수적 운영**: 오탐 최소화를 위해 높은 임계치 유지
- **간결한 주입**: 회귀 컨텍스트는 1~3줄로 제한하여 프롬프트 부풀림 방지

---

## 3. MODE 태그 출력 완전 제거

### 3.1 문제점
- `[MODE: SAJU]`, `[MODE: COUNSEL]` 태그가 LLM 출력에 노출되어 맥락 리셋 유발
- 내부 분기용 태그가 사용자에게 노출됨

### 3.2 수정 내용
- **MODE 태그는 내부 분기용으로만 사용**, LLM 출력에서 완전 제거
- 프롬프트에서 "답변은 자연스럽게 시작한다" 규칙 명시
- 공통 최소 규칙에서 모드 태그 관련 문구 제거

---

## 4. 회귀 컨텍스트 주입 최적화

### 4.1 수정 내용
- **요약 주입 1~3줄 제한** 강제 적용
- `context_lines[:3]` 슬라이싱으로 최대 3줄까지만 주입
- 태그 형식(`[이전 결론]`) 피하고 자연스러운 문장으로 주입
  - 예: "이전 대화 요약: ...", "현재 질문은 이전 결론을 전제로 함: ..."

---

## 5. 수정된 파일 목록

### 5.1 functions/regress_Deixis.py
- `_is_continuation_by_structure()` (Rule 기반) 완전 제거
- `_llm_detect_continuation()` (LLM 기반) 추가
- `CONTINUATION_THRESHOLD = 0.75` 적용
- 요약 주입 로직에 `[:3]` 제한 추가

### 5.2 functions/prompts/saju_prompts.py
- MODE 태그 출력 관련 규칙 완전 제거
- "답변은 자연스럽게 시작한다" 규칙 명시
- 공통 최소 규칙에서 모드 태그 문구 제거

---

## 6. 실전 케이스 개선

| 질문 유형 | v3.0 (Rule) | v4.0 (LLM) |
|----------|-------------|------------|
| "둘중에 하나만 고르라면?" | ❌ 0.10 (놓침) | ✅ 0.95 (감지) |
| "왜?" (판단형 후) | ✅ 0.88 | ✅ 0.90 |
| "건강운은?" (새 주제) | ❌ 0.05 | ✅ 0.15 (의도대로) |

---

## 7. 참고 문서
- `LLM_SEMANTIC_DETECTION_v4.0.md`: 상세 설계 문서
