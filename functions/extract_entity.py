from datetime import datetime
import re
from typing import List, Dict, Optional, Tuple
import json

FACT_KEYS = ["ì¢…ëª©ëª…","ì¸ë¬¼","íƒ€ê²Ÿ_ì—°ë„","íƒ€ê²Ÿ_ì›”","íƒ€ê²Ÿ_ì¼","íƒ€ê²Ÿ_ì‹œ","ê°„ì§€","í‚¤ì›Œë“œ"]
EVENT_SYNONYMS: dict[str, list[str]] = {
    "ë©´ì ‘": ["ë©´ì ‘", "ì¸í„°ë·°"],
    "ê²°í˜¼": ["ê²°í˜¼ì‹", "ì›¨ë”©", "ê²°í˜¼"],
    "ì—¬í–‰": ["í•´ì™¸ì—¬í–‰", "êµ­ë‚´ì—¬í–‰", "ì—¬í–‰ìš´", "ì¶œì¥", "ì—¬í–‰", "íœ´ê°€", "íŠ¸ë¦½", "trip"],
    "ì‹œí—˜": ["ì‹œí—˜", "ìˆ˜ëŠ¥", "ìê²©ì¦", "ê³ ì‹œ"],
    "ìƒì¼": ["ìƒì¼", "ìƒì‹ ", "birthday", "ëŒì”ì¹˜", "ëŒ"],
    "ê¸°ë…ì¼": ["ê¸°ë…ì¼", "anniversary"],
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) ìœ í‹¸: ì¤‘ë³µ ì œê±°
def _dedup_list(items):
    seen, out = set(), []
    for x in items:
        x = (x or "").strip()
        if not x:
            continue
        if x.lower() in seen:
            continue
        seen.add(x.lower())
        out.append(x)
    return out

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) ì´ë²¤íŠ¸ ì •ê·œí™”
def _normalize_event_kind(kind: str) -> str:
    k = (kind or "").strip().lower()
    if not k:
        return k
    mapping = {
        "ë©´ì ‘": "ë©´ì ‘", "ì¸í„°ë·°": "ë©´ì ‘",
        "ê²°í˜¼": "ê²°í˜¼", "ê²°í˜¼ì‹": "ê²°í˜¼", "ì›¨ë”©": "ê²°í˜¼",
        "ì—¬í–‰": "ì—¬í–‰", "ì¶œì¥": "ì—¬í–‰",
        "ì‹œí—˜": "ì‹œí—˜", "ìˆ˜ëŠ¥": "ì‹œí—˜", "ìê²©ì¦": "ì‹œí—˜",
        "ìƒì¼": "ìƒì¼", "ëŒ": "ìƒì¼", "ìƒì‹ ": "ìƒì¼", "birthday": "ìƒì¼",
        "ê¸°ë…ì¼": "ê¸°ë…ì¼", "anniversary": "ê¸°ë…ì¼"
    }
    for key in sorted(mapping.keys(), key=len, reverse=True):
        if key in k:
            return mapping[key]
    return kind.strip()

def _normalize_date(s: str) -> str:
    if not s:
        return s
    raw = s.strip()
    try:
        for fmt in ("%Y-%m-%d", "%Y/%m/%d", "%Y.%m.%d"):
            try:
                return datetime.strptime(raw, fmt).strftime("%Y-%m-%d")
            except:
                pass
        m = re.match(r"(\d{4})\s*ë…„\s*(\d{1,2})\s*ì›”\s*(\d{1,2})\s*ì¼", raw)
        if m:
            y, mo, d = map(int, m.groups())
            return f"{y:04d}-{mo:02d}-{d:02d}"
        return raw
    except:
        return raw
def _ensure_dict(obj, default=None):
    """objê°€ dictê°€ ì•„ë‹ˆì–´ë„ ìµœëŒ€í•œ dictë¡œ ë³€í™˜ (str JSON ì§€ì›). ì‹¤íŒ¨ ì‹œ default ë°˜í™˜."""
    if isinstance(obj, dict):
        return obj
    if isinstance(obj, str):
        try:
            parsed = json.loads(obj)
            if isinstance(parsed, dict):
                return parsed
        except Exception:
            pass
    return {} if default is None else default

def _normalize_events(evts) -> list[dict]:
    """evtsê°€ list/dict/str/JSON ë“± ì–´ë–¤ í˜•ì‹ì´ ì™€ë„
    [{'ì¢…ë¥˜':..., 'ë‚ ì§œ':..., 'ì„¤ëª…':...}] ë¦¬ìŠ¤íŠ¸ë¡œ ì •ê·œí™”."""
    out: list[dict] = []

    if not evts:
        return out

    # JSON ë¬¸ìì—´ì´ë©´ íŒŒì‹±
    if isinstance(evts, str):
        try:
            maybe = json.loads(evts)
            return _normalize_events(maybe)
        except Exception:
            # ê·¸ëƒ¥ 'ì—¬í–‰' ê°™ì€ ë‹¨ì¼ ë¬¸ìì—´ë¡œ ê°„ì£¼
            evts = [evts]

    # ë‹¨ì¼ dictë©´ ë¦¬ìŠ¤íŠ¸í™”
    if isinstance(evts, dict):
        evts = [evts]

    if not isinstance(evts, list):
        return out

    for e in evts:
        if isinstance(e, str):
            e = {"ì¢…ë¥˜": e}
        if not isinstance(e, dict):
            continue

        kind = _normalize_event_kind(e.get("ì¢…ë¥˜", ""))
        date = _normalize_date(e.get("ë‚ ì§œ", ""))
        desc = (e.get("ì„¤ëª…") or "").strip()

        if not kind:
            continue

        item = {"ì¢…ë¥˜": kind}
        if date:
            item["ë‚ ì§œ"] = date
        if desc:
            item["ì„¤ëª…"] = desc
        out.append(item)

    return out


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) FACTS ë³‘í•©
def _merge_entities(base: dict, new: dict) -> dict:
    print("\n[MERGE] start")

    # âš ï¸ ë°©ì–´: ë¬¸ìì—´/ì—‰ëš±í•œ íƒ€ì…ì´ ë“¤ì–´ì™€ë„ dictë¡œ ê°•ì œ
    base = _ensure_dict(base, {})
    new  = _ensure_dict(new,  {})

    merged = {
        k: list(base.get(k, []))
        for k in ["ì¢…ëª©ëª…","ì¸ë¬¼","íƒ€ê²Ÿ_ì—°ë„","íƒ€ê²Ÿ_ì›”","íƒ€ê²Ÿ_ì¼","íƒ€ê²Ÿ_ì‹œ","ê°„ì§€","í‚¤ì›Œë“œ"]
    }

    for k, vals in (new or {}).items():
        if k in merged:
            merged[k].extend(vals or [])
            merged[k] = _dedup_list(merged[k])[:8]

    # ì´ë²¤íŠ¸ë„ ì–´ë–¤ í˜•ì‹ì´ ì™€ë„ ì •ê·œí™”í•´ì„œ ë³‘í•©
    base_events = _normalize_events(base.get("ì´ë²¤íŠ¸", []))
    new_events  = _normalize_events(new.get("ì´ë²¤íŠ¸", []))

    try:
        print(f"base_events : {base_events} , new_events : {new_events}")
        print(f"[MERGE] events base={len(base_events)} new={len(new_events)}")
    except Exception:
        pass

    seen = set()
    merged_events = []
    for e in base_events + new_events:
        key = (e.get("ì¢…ë¥˜",""), e.get("ë‚ ì§œ",""), e.get("ì„¤ëª…",""))
        if key in seen:
            continue
        seen.add(key)
        merged_events.append(e)

    merged["ì´ë²¤íŠ¸"] = merged_events[:20]
    print(f"[MERGE] events merged={len(merged['ì´ë²¤íŠ¸'])}")
    return merged


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4) FACTS í¬ë§·íŒ…
FACTS_HEADER = "ğŸ“Œ FACTS(ì—”í‹°í‹°):"

def _format_facts_block(facts: dict) -> str:
    print(f"[FACTS] formatting keys: {list(facts.keys())}")
    facts = facts or {}
    lines = [
        FACTS_HEADER,
        f"- ì¸ë¬¼: {', '.join(facts.get('ì¸ë¬¼', [])) or 'ì—†ìŒ'}",
        f"- ì¢…ëª©ëª…: {', '.join(facts.get('ì¢…ëª©ëª…', [])) or 'ì—†ìŒ'}",
        f"- íƒ€ê²Ÿ_ì—°ë„: {', '.join(facts.get('íƒ€ê²Ÿ_ì—°ë„', [])) or 'ì—†ìŒ'}",
        f"- íƒ€ê²Ÿ_ì›”: {', '.join(facts.get('íƒ€ê²Ÿ_ì›”', [])) or 'ì—†ìŒ'}",
        f"- íƒ€ê²Ÿ_ì¼: {', '.join(facts.get('íƒ€ê²Ÿ_ì¼', [])) or 'ì—†ìŒ'}",
        f"- íƒ€ê²Ÿ_ì‹œ: {', '.join(facts.get('íƒ€ê²Ÿ_ì‹œ', [])) or 'ì—†ìŒ'}",
        f"- ê°„ì§€: {', '.join(facts.get('ê°„ì§€', [])) or 'ì—†ìŒ'}",
        f"- í‚¤ì›Œë“œ: {', '.join(facts.get('í‚¤ì›Œë“œ', [])) or 'ì—†ìŒ'}",
        f"- ì´ë²¤íŠ¸:"
    ]
    events = facts.get("ì´ë²¤íŠ¸", []) or []
    if not events:
        lines.append("  (ì—†ìŒ)")
    else:
        for e in events:
            lines.append(f"  - ì¢…ë¥˜: {e.get('ì¢…ë¥˜','')}")
            if e.get("ë‚ ì§œ"):  lines.append(f"    ë‚ ì§œ: {e['ë‚ ì§œ']}")
            if e.get("ì„¤ëª…"):  lines.append(f"    ì„¤ëª…: {e['ì„¤ëª…']}")
    return "\n".join(lines)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5) FACTS íŒŒì‹±
def _dedup_events(evts: list[dict]) -> list[dict]:
    seen = set()
    out = []
    for e in evts or []:
        key = (e.get("ì¢…ë¥˜",""), e.get("ë‚ ì§œ",""), e.get("ì„¤ëª…",""))
        if key in seen:
            continue
        seen.add(key)
        out.append(e)
    return out

def _parse_facts_from_summary(summary: str) -> dict:
    print("[PARSE] start")
    print(f"[PARSE] summary : {summary}")
    base = {k: [] for k in ["ì¢…ëª©ëª…","ì¸ë¬¼","íƒ€ê²Ÿ_ì—°ë„","íƒ€ê²Ÿ_ì›”","íƒ€ê²Ÿ_ì¼","íƒ€ê²Ÿ_ì‹œ","ê°„ì§€","í‚¤ì›Œë“œ"]}
    base["ì´ë²¤íŠ¸"] = []
    if not summary or FACTS_HEADER not in summary:
        print("[PARSE] header not found â†’ return empty")
        return base

    # âœ… ìš”ì•½ì— FACTS ë¸”ë¡ì´ ì—¬ëŸ¬ ë²ˆ ë“¤ì–´ìˆì–´ë„ "ê°€ì¥ ë§ˆì§€ë§‰" ê²ƒë§Œ íŒŒì‹±
    block = summary.rsplit(FACTS_HEADER, 1)[1]
    lines = [l.rstrip() for l in block.splitlines()]

    simple_keys = {
        "ì¸ë¬¼": "ì¸ë¬¼",
        "ì¢…ëª©ëª…": "ì¢…ëª©ëª…",
        "íƒ€ê²Ÿ_ì—°ë„": "íƒ€ê²Ÿ_ì—°ë„",
        "íƒ€ê²Ÿ_ì›”": "íƒ€ê²Ÿ_ì›”",
        "íƒ€ê²Ÿ_ì¼": "íƒ€ê²Ÿ_ì¼",
        "íƒ€ê²Ÿ_ì‹œ": "íƒ€ê²Ÿ_ì‹œ",
        "ê°„ì§€": "ê°„ì§€",
        "í‚¤ì›Œë“œ": "í‚¤ì›Œë“œ",
    }

    i = 0
    print(f"len {lines}")
    while i < len(lines):
        ln = lines[i].strip()

        # ğŸš« ë°©ì–´: í˜¹ì‹œ ë˜ ë‹¤ë¥¸ FACTS í—¤ë”ê°€ ë‚˜ì˜¤ë©´ ê·¸ ë’¤ëŠ” ë¬´ì‹œ
        if ln.startswith(FACTS_HEADER):
            break

        for label, key in simple_keys.items():
            if ln.startswith(f"- {label}:"):
                vals = ln.split(":", 1)[1].strip()
                items = [v.strip() for v in vals.split(",") if v.strip() and v.strip() != "ì—†ìŒ"]
                base[key] = items
                print(f"[PARSE] {label} â† {items}")

        if ln.startswith("- ì´ë²¤íŠ¸:"):
            i += 1
            # ë“¤ì—¬ì“°ê¸° 2ì¹¸(ìŠ¤í˜ì´ìŠ¤) ê¸°ë°˜ í•˜ìœ„ ë¼ì¸ íŒŒì‹± ìœ ì§€
            while i < len(lines) and lines[i].startswith("  "):
                if lines[i].strip().startswith("- ì¢…ë¥˜:"):
                    kind = lines[i].split(":", 1)[1].strip()
                    evt = {"ì¢…ë¥˜": _normalize_event_kind(kind)}
                    j = i + 1
                    while j < len(lines) and lines[j].startswith("    "):
                        sub = lines[j].strip()
                        if sub.startswith("ë‚ ì§œ:"):
                            evt["ë‚ ì§œ"] = _normalize_date(sub.split(":", 1)[1].strip())
                        elif sub.startswith("ì„¤ëª…:"):
                            evt["ì„¤ëª…"] = sub.split(":", 1)[1].strip()
                        j += 1
                    base["ì´ë²¤íŠ¸"].append(evt)
                  #  print(f"[PARSE] event +1 {evt}")
                    i = j - 1
        i += 1

    # âœ… íŒŒì‹± ê²°ê³¼ ì •ê·œí™” + ì¤‘ë³µ ì œê±°(ì´ì „ ìš”ì•½ì— ì¤‘ë³µ FACTSê°€ ìˆì—ˆì–´ë„ ì—¬ê¸°ì„œ ì •ë¦¬)
    base["ì´ë²¤íŠ¸"] = _dedup_events(_normalize_events(base.get("ì´ë²¤íŠ¸", [])))

    print("[PARSE] end", {k: len(v) for k,v in base.items()})
    return base

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6) summaryì— FACTS ë³‘í•©
def enrich_summary_with_entities(prev_summary: str, new_entities: dict, keep_tail_chars: int = 1200) -> str:
    print("[FACTS] enrich start")
    print("[FACTS] --- enrich_summary_with_entities ì‹œì‘ ---")
    print(f"[FACTS] ì´ì „ summary ê¸¸ì´: {len(prev_summary) if prev_summary else 0}")
    print(f"[FACTS] ì‹ ê·œ ì—”í‹°í‹° ì…ë ¥: {json.dumps(new_entities, ensure_ascii=False)}")
    prev_summary = prev_summary or ""
    if FACTS_HEADER in prev_summary:
        prev_body = prev_summary.split(FACTS_HEADER, 1)[0].rstrip()
        print("[FACTS] header found â†’ split body")
        print(f"prev_body : {prev_body}")
        print(f"prev_summary : {prev_summary}")
    else:
        prev_body = prev_summary.strip()
        print("[FACTS] no header â†’ body only")
        print(f"prev_body : {prev_body}")        
    if len(prev_body) > keep_tail_chars:
        prev_body = prev_body[-keep_tail_chars:]
        print(f"[FACTS] body trimmed to {keep_tail_chars} chars")
        
    old_facts = _parse_facts_from_summary(prev_summary)
    merged = _merge_entities(old_facts, new_entities)
       # ğŸŸ¡ ë””ë²„ê¹… ë¡œê·¸
    print("===== FACTS Debug Log =====")
    print(f"[FACTS] ì‹ ê·œ ì—”í‹°í‹° ì…ë ¥: {new_entities}")
    print(f"[FACTS] ê¸°ì¡´ FACTS íŒŒì‹± ê²°ê³¼: {old_facts}")
    print(f"[FACTS] ë³‘í•©ëœ FACTS ê²°ê³¼: {merged}")
    print("============================")

    parts = [prev_body.strip(), "", _format_facts_block(merged)]
    print(f"parts : {parts}")
    result = "\n".join([p for p in parts if p is not None]).strip()
    print(f"result : {result}")
    print("[FACTS] enrich end")
    return result

# 2) ì´ë²¤íŠ¸ ì¶”ì¶œê¸° (ëª¨ë“œì™€ ë¬´ê´€í•˜ê²Œ í•­ìƒ ì‹¤í–‰)
def _extract_events_from_text(text: str,  payload: dict | None) -> list[str]:
    t = (text or "").strip().lower()
    if not t:
        return []
    found = set()
    # í•œê¸€ ë³´í˜¸: ë³„ë„ í† í°í™” ì—†ì´ ë¶€ë¶„ í¬í•¨ë„ í—ˆìš©
    for canon, words in EVENT_SYNONYMS.items():
        if any(w in t for w in words):
            found.add(canon)
    return list(found)

def _build_event_desc_from_payload(payload: dict | None) -> str:
    if not payload:
        return ""
    tt = (payload.get("target_time") or {})
    y = (tt.get("year")  or {}).get("ganji")
    m = (tt.get("month") or {}).get("ganji")
    d = (tt.get("day")   or {}).get("ganji")
    h = (tt.get("hour")  or {}).get("ganji")
    parts = [p for p in [y,m,d,h] if p]
    return f"íƒ€ê²Ÿ ê°„ì§€: {' '.join(parts)}" if parts else ""

def _scan_event_kinds(text: str) -> list[str]:
    """ì‚¬ìš©ì ë¬¸ì¥ ì•ˆì—ì„œ ì´ë²¤íŠ¸ ì˜ë„(ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)ë¥¼ ì¶”ì¶œí•´ í‘œì¤€ ì´ë²¤íŠ¸ëª…ìœ¼ë¡œ ë°˜í™˜."""
    if not text:
        return []
    t = text.strip().lower()
    found = []
    for canon, words in EVENT_SYNONYMS.items():
        for w in sorted(words, key=len, reverse=True):
            if w in t:
                found.append(canon)
                break  # ê°™ì€ canon ì¤‘ë³µ ë°©ì§€
    return _dedup_list(found)

# ===== [D] extract_entities_for_summary ì¸ìí™”, ì•ˆì „í™” =====
def extract_entities_for_summary(user_text: str, assistant_text: str, payload: dict | None = None) -> dict:
    print("\n[ENTITIES] --- extract_entities_for_summary ì‹œì‘ ---")
    print(f"[ENTITIES] ì‚¬ìš©ì ì…ë ¥: {user_text}")
    print(f"[ENTITIES] AI ì‘ë‹µ: {assistant_text}")    
    
    ents = {k: [] for k in FACT_KEYS + ["ì´ë²¤íŠ¸"]}
    #print(f"ents_2 {ents}") //ì¶œë ¥ : ents_2 {'ì¢…ëª©ëª…': [], 'ì¸ë¬¼': [], 'íƒ€ê²Ÿ_ì—°ë„': [], 'íƒ€ê²Ÿ_ì›”': [], 'íƒ€ê²Ÿ_ì¼': [], 'íƒ€ê²Ÿ_ì‹œ': [], 'ê°„ì§€': [], 'í‚¤ì›Œë“œ': [], 'ì´ë²¤íŠ¸': []}

    # âœ… payload.target_timeì—ì„œ ê°„ì§€ ë³´ê°• (ì—†ìœ¼ë©´ skip)
    if payload:
        tt = (payload.get("target_time") or {})        
        y = (tt.get("year")  or {}).get("ganji")
        m = (tt.get("month") or {}).get("ganji")
        d = (tt.get("day")   or {}).get("ganji")
        h = (tt.get("hour")  or {}).get("ganji")
        #print(f"tt : {tt} y:{y}, m:{m}, d:{d}") 
        # ì¶œë ¥ :tt : {'year': {'ganji': 'ä¹™å·³', 'sipseong': None, 'sibi_unseong': None}, 'month': {'ganji': 'ç”²ç”³', 'sipseong': None, 'sibi_unseong': None}, 'day': {'ganji': 'å£¬åˆ', 'sipseong': None, 'sibi_unseong': None}, 'hour': {'ganji': None, 'sipseong': None, 'sibi_unseong': None}} 
                                                #y:ä¹™å·³, m:ç”²ç”³, d:å£¬åˆ        
        if y: ents["íƒ€ê²Ÿ_ì—°ë„"].append(y); ents["ê°„ì§€"].append(y)
        if m: ents["íƒ€ê²Ÿ_ì›”"].append(m);   ents["ê°„ì§€"].append(m)
        if d: ents["íƒ€ê²Ÿ_ì¼"].append(d);   ents["ê°„ì§€"].append(d)
        if h: ents["íƒ€ê²Ÿ_ì‹œ"].append(h);   ents["ê°„ì§€"].append(h)
    

    # ì¤‘ë³µ ì œê±° & ìƒí•œ
    for k in FACT_KEYS:
        ents[k] = _dedup_list(ents.get(k, []))[:8]

    # ì´ë²¤íŠ¸ ì¶”ì¶œ â†’ dictë¡œ ì €ì¥ + ê°„ì§€ ì„¤ëª… ë¶€ì—¬
    kinds = _scan_event_kinds(user_text)  # ex) ["ì—¬í–‰"]
    if kinds:
        desc = _build_event_desc_from_payload(payload)
        ents["ì´ë²¤íŠ¸"] = [{"ì¢…ë¥˜": k, **({"ì„¤ëª…": desc} if desc else {})} for k in kinds]
        
    # [FIX] ì´ë²¤íŠ¸ëŠ” ë¶„ë¥˜/ëª¨ë“œì™€ ë¬´ê´€í•˜ê²Œ í•­ìƒ ì¶”ì¶œ
    extracted = _extract_events_from_text(user_text, payload)
    if extracted:
        ents["ì´ë²¤íŠ¸"] = extracted


    #print(f"[ENTITIES] --- ents: {ents} ---\n") ì¶œë ¥ : [ENTITIES] --- ents: {'ì¢…ëª©ëª…': [], 'ì¸ë¬¼': [], 'íƒ€ê²Ÿ_ì—°ë„': ['ä¹™å·³'], 'íƒ€ê²Ÿ_ì›”': ['ç”²ç”³'], 'íƒ€ê²Ÿ_ì¼': ['å£¬åˆ'], 'íƒ€ê²Ÿ_ì‹œ': [], 'ê°„ì§€': ['ä¹™å·³', 'ç”²ç”³', 'å£¬åˆ'], 'í‚¤ì›Œë“œ': [], 'ì´ë²¤íŠ¸': []} ---
    print("[ENTITIES] --- extract_entities_for_summary ë ---\n")
    return ents


# ===== [C] wanted ì´ë²¤íŠ¸ ì¢…ë¥˜ ê°„ë‹¨ ì¶”ì¶œê¸° =====
# ì§ˆë¬¸ì—ì„œ íŠ¹ì • ì´ë²¤íŠ¸ ì˜ë„ë¥¼ ì¶”ì¶œ (ë£° ê¸°ë°˜ í‚¤ì›Œë“œ ë§¤ì¹­)
def _wanted_event_kind(text: str) -> str | None:
    if not text:
        return None
    t = text.strip().lower()
    print(f"_wanted_event_kind {t}")
    # ìš°ì„ ìˆœìœ„ê°€ ê²¹ì¹  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ê¸´ í‚¤ì›Œë“œ ë¨¼ì € ì²´í¬
    rules = [
        # (í‚¤ì›Œë“œë“¤, ì •ê·œí™”ëœ ì´ë²¤íŠ¸ëª…)
        (["ë©´ì ‘", "ì¸í„°ë·°"], "ë©´ì ‘"),
        (["ê²°í˜¼ì‹", "ì›¨ë”©", "ê²°í˜¼"], "ê²°í˜¼"),
        (["ì¶œì¥", "ì—¬í–‰"], "ì—¬í–‰"),
        (["ì‹œí—˜", "ìˆ˜ëŠ¥", "ìê²©ì¦", "ê³ ì‹œ"], "ì‹œí—˜"),
        (["ìƒì¼", "ìƒì‹ ", "birthday", "ëŒì”ì¹˜", "ëŒ"], "ìƒì¼"),
        (["ê¸°ë…ì¼", "anniversary"], "ê¸°ë…ì¼"),
    ]
    for keywords, kind in rules:
        for kw in keywords:
            if kw in t:
                return kind
    return None

def _fallback_desc_from_facts(facts: dict) -> str:
    def last(key):
        v = facts.get(key, [])
        return v[-1] if v else None
    y, m, d, h = last("íƒ€ê²Ÿ_ì—°ë„"), last("íƒ€ê²Ÿ_ì›”"), last("íƒ€ê²Ÿ_ì¼"), last("íƒ€ê²Ÿ_ì‹œ")
    parts = [p for p in [y,m,d,h] if p]
    return f"íƒ€ê²Ÿ ê°„ì§€(ì¶”ì •): {' '.join(parts)}" if parts else ""

def quick_lookup_from_facts(question: str, summary_text: str) -> str | None:
    kind = _wanted_event_kind(question)
    if not kind:
        return None
    print(f"kind : {kind}")
    facts = _parse_facts_from_summary(summary_text)

    # ê°€ì¥ ìµœê·¼ í•´ë‹¹ ì´ë²¤íŠ¸
    target = None
    for e in reversed(facts.get("ì´ë²¤íŠ¸", [])):
        if _normalize_event_kind(e.get("ì¢…ë¥˜","")) == _normalize_event_kind(kind):
            target = e
            break
    if not target:
        return None

    date = target.get("ë‚ ì§œ")
    desc = target.get("ì„¤ëª…")
    if not date and not desc:
        # ğŸ”¹ ê³¼ê±° ì´ë²¤íŠ¸ê°€ ë¹„ì–´ìˆìœ¼ë©´ FACTSì˜ ìµœì‹  ê°„ì§€ë¡œ ì„¤ëª… í´ë°±
        desc = _fallback_desc_from_facts(facts)

    lines = ["[MODE: LOOKUP]"]
    lines.append(f"- {kind} ë‚ ì§œ: {date if date else 'ë‚ ì§œ ì •ë³´ ì—†ìŒ'}")
    if desc:
        lines.append(f"- ë©”ëª¨: {desc}")
    return "\n".join(lines)


# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# # 8) record_turn
# global_summary = ""

# def record_turn(user_text: str, assistant_text: str):
#     global global_summary
#     print("\n================= record_turn start =================")
#     print(f"[TURN] user: {user_text}")
#     print(f"[TURN] assistant: {assistant_text[:100]}{'...' if len(assistant_text)>100 else ''}")
#     prev_summary = global_summary
#     ents = extract_entities_for_summary(user_text, assistant_text)
#     print(f"[TURN] ents={ents}")
#     new_summary = enrich_summary_with_entities(prev_summary, ents, keep_tail_chars=1200)
#     global_summary = new_summary
#     print("[TURN] roundtrip summary head:")
#     print(global_summary[:300])
#     print("================== record_turn end ==================\n")
